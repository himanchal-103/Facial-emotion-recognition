{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSeft6W5pclG",
    "outputId": "0fc5dfda-a39e-4fb4-ea34-1d2a887bb1ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'facial_expressions'...\n",
      "remote: Enumerating objects: 14214, done.\u001b[K\n",
      "remote: Total 14214 (delta 0), reused 0 (delta 0), pack-reused 14214\u001b[K\n",
      "Receiving objects: 100% (14214/14214), 239.65 MiB | 4.73 MiB/s, done.\n",
      "Resolving deltas: 100% (223/223), done.\n",
      "Updating files: 100% (13996/13996), done.\n"
     ]
    }
   ],
   "source": [
    "# github repository for images for training model\n",
    "!git clone https://github.com/muxspace/facial_expressions.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O8710QSYpiJj"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "data = {}\n",
    "with open('facial_expressions/data/legend.csv') as f:\n",
    "  reader = csv.reader(f)\n",
    "  next(reader)\n",
    "  for row in reader:\n",
    "    key = row[2].lower()\n",
    "    if key in data:\n",
    "      data[key].append(row[1])\n",
    "    else:\n",
    "      data[key] = [row[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6el4-OEpiPz",
    "outputId": "99e08f17-4310-45ba-88c2-29ba5c28c8e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'neutral',\n",
       " 'happiness',\n",
       " 'sadness',\n",
       " 'contempt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of facial expressions \n",
    "emotion_list = list(data.keys())\n",
    "emotion_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xDu5maU-piSd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('master_data')\n",
    "os.mkdir('master_data/training')\n",
    "os.mkdir('master_data/testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pkGX1dv1piU6"
   },
   "outputs": [],
   "source": [
    "for emotion in emotion_list:\n",
    "  os.mkdir(os.path.join('master_data/training', emotion))\n",
    "  os.mkdir(os.path.join('master_data/testing', emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jElkosCgpiZK"
   },
   "outputs": [],
   "source": [
    "# dividing training and testing data\n",
    "\n",
    "from shutil import copyfile\n",
    "split_size = 0.8\n",
    "\n",
    "for emotion, images in data.items():\n",
    "  train_size = int(split_size * len(images))\n",
    "  train_images = images[:train_size]\n",
    "  test_images = images[train_size:]\n",
    "\n",
    "  for image in train_images:\n",
    "    source = os.path.join('facial_expressions/images', image)\n",
    "    dest = os.path.join('master_data/training', emotion, image)\n",
    "    copyfile(source, dest)\n",
    "  \n",
    "  for image in train_images:\n",
    "    source = os.path.join('facial_expressions/images', image)\n",
    "    dest = os.path.join('master_data/testing', emotion, image)\n",
    "    copyfile(source, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rZKO2kfqpib0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-15 13:47:12.944769: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8xMeL1RMpieU",
    "outputId": "70c28fa0-08b7-49c3-d40c-06c309f5bea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 98, 98, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3277312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,305,000\n",
      "Trainable params: 3,305,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "model = tf.keras.models.Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.01), loss='categorical_crossentropy', metrics=['accuracy']) # accuracy == acc\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gS_GBt_3pigq",
    "outputId": "ba221ef4-9c86-4757-8e9a-5815cdffcc9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10941 images belonging to 8 classes.\n",
      "Found 10941 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir  = 'master_data/training'\n",
    "test_dir = 'master_data/testing'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(100,100),\n",
    "    class_mode='categorical',\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(100,100),\n",
    "    class_mode='categorical',\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8tFdgtfLJ3AQ"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_acc', patience=2, min_delta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AVQXv7OJ2-R",
    "outputId": "608052fe-f4bb-4a53-99ea-0fb11c32b859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 1.2615 - accuracy: 0.4784WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "86/86 [==============================] - 33s 380ms/step - loss: 1.2615 - accuracy: 0.4784 - val_loss: 1.1354 - val_accuracy: 0.5018\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 1.0296 - accuracy: 0.4918WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "86/86 [==============================] - 33s 379ms/step - loss: 1.0296 - accuracy: 0.4918 - val_loss: 0.9815 - val_accuracy: 0.5485\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.8473 - accuracy: 0.6575WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "86/86 [==============================] - 32s 377ms/step - loss: 0.8473 - accuracy: 0.6575 - val_loss: 0.6835 - val_accuracy: 0.7486\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.7469WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "86/86 [==============================] - 34s 393ms/step - loss: 0.6844 - accuracy: 0.7469 - val_loss: 0.6118 - val_accuracy: 0.7760\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6220 - accuracy: 0.7723WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "86/86 [==============================] - 34s 395ms/step - loss: 0.6220 - accuracy: 0.7723 - val_loss: 0.5867 - val_accuracy: 0.7863\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.7809WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "86/86 [==============================] - 34s 395ms/step - loss: 0.6110 - accuracy: 0.7809 - val_loss: 0.5965 - val_accuracy: 0.7809\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.8003WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "86/86 [==============================] - 34s 394ms/step - loss: 0.5644 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.8141\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.8086WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "86/86 [==============================] - 34s 395ms/step - loss: 0.5317 - accuracy: 0.8086 - val_loss: 0.4895 - val_accuracy: 0.8223\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.8154WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "86/86 [==============================] - 34s 398ms/step - loss: 0.5139 - accuracy: 0.8154 - val_loss: 0.5267 - val_accuracy: 0.8088\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.8195WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "86/86 [==============================] - 34s 400ms/step - loss: 0.4955 - accuracy: 0.8195 - val_loss: 0.4785 - val_accuracy: 0.8220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f838d1eb5b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=10, verbose=1, validation_data=test_generator, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "w7fHLR8fJ28A"
   },
   "outputs": [],
   "source": [
    "# saving the model\n",
    "model.save('facial_emotion_recognition_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q17cRQq0pijT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7REMopiZpila"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgRWn5GNpin7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-oN66YVGpiqX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vt7xHYsfpis5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMFR1WrlpivN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
